{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "8tQJd2YSCfWR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "D7tqLMoKF6uq"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 6\n",
    "------------\n",
    "\n",
    "After training a skip-gram model in `5_word2vec.ipynb`, the goal of this notebook is to train a LSTM character model over [Text8](http://mattmahoney.net/dc/textdata) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "\n",
    "(difficult!)\n",
    "\n",
    "Write a sequence-to-sequence LSTM which mirrors all the words in a sentence. For example, if your input is:\n",
    "\n",
    "    the quick brown fox\n",
    "    \n",
    "the model should attempt to output:\n",
    "\n",
    "    eht kciuq nworb xof\n",
    "    \n",
    "Refer to the lecture on how to put together a sequence-to-sequence model, as well as [this article](http://arxiv.org/abs/1409.3215) for best practices.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "MvEblsgEXxrd"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "executionInfo": {
     "elapsed": 5993,
     "status": "ok",
     "timestamp": 1445965582896,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "RJ-o3UBUFtCw",
    "outputId": "d530534e-0791-4a94-ca6d-1c8f1b908a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mattmahoney.net/dc/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if not os.path.exists(filename):\n",
    "    filename, _ = urlretrieve(url + filename, filename)\n",
    "  statinfo = os.stat(filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified %s' % filename)\n",
    "  else:\n",
    "    print(statinfo.st_size)\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "filename = maybe_download('text8.zip', 31344016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "executionInfo": {
     "elapsed": 5982,
     "status": "ok",
     "timestamp": 1445965582916,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "Mvf09fjugFU_",
    "outputId": "8f75db58-3862-404b-a0c3-799380597390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 100000000\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "  with zipfile.ZipFile(filename) as f:\n",
    "    name = f.namelist()[0]\n",
    "    data = tf.compat.as_str(f.read(name))\n",
    "  return data\n",
    "  \n",
    "text = read_data(filename)\n",
    "print('Data size %d' % len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "ga2CYACE-ghb"
   },
   "source": [
    "Create a small validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "executionInfo": {
     "elapsed": 6184,
     "status": "ok",
     "timestamp": 1445965583138,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "w-oBpfFG-j43",
    "outputId": "bdb96002-d021-4379-f6de-a977924f0d02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99995000  of one eight four eight in france proudhon s philosophy of prop\n",
      "5000  anarchism originated as a term of abuse first used against earl\n"
     ]
    }
   ],
   "source": [
    "valid_size = 5000\n",
    "valid_text = text[:valid_size]\n",
    "train_text = text[valid_size:]\n",
    "train_size = len(train_text)\n",
    "print(train_size, train_text[:64])\n",
    "print(valid_size, valid_text[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "Zdw6i4F8glpp"
   },
   "source": [
    "Utility functions to map characters to vocabulary IDs and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "executionInfo": {
     "elapsed": 6276,
     "status": "ok",
     "timestamp": 1445965583249,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "gAL1EECXeZsD",
    "outputId": "88fc9032-feb9-45ff-a9a0-a26759cc1f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected character: ï\n",
      "3 28 0 0 1\n",
      "<go> x  \n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(string.ascii_lowercase) + 3 # [a-z] + ' ' + ~(eos) + '^(go)' (https://www.tensorflow.org/tutorials/seq2seq/)\n",
    "first_letter = ord(string.ascii_lowercase[0])\n",
    "\n",
    "def char2id(char):\n",
    "  if char in string.ascii_lowercase:\n",
    "    return ord(char) - first_letter + 3\n",
    "  elif char == ' ':\n",
    "    return 0\n",
    "  elif char == '^': # <go>\n",
    "    return 1\n",
    "  elif char == '~': # <eos>\n",
    "    return 2\n",
    "  else:\n",
    "    print('Unexpected character: %s' % char)\n",
    "    return 0\n",
    "  \n",
    "def id2char(dictid):\n",
    "  if dictid > 2:\n",
    "    return chr(dictid + first_letter - 3)\n",
    "  elif dictid == 1:\n",
    "        return '<go>'\n",
    "  elif dictid == 2:\n",
    "    return '<eos>'\n",
    "  else:\n",
    "    return ' '\n",
    "\n",
    "print(char2id('a'), char2id('z'), char2id(' '), char2id('ï'), char2id('^'))\n",
    "print(id2char(1), id2char(26), id2char(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eht kciuq nworb xof'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mirror_words(sentence):\n",
    "    return ' '.join([word[::-1] for word in sentence.split(' ')])\n",
    "mirror_words('the quick brown fox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "lFwoyygOmWsL"
   },
   "source": [
    "Function to generate a training batch for the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "executionInfo": {
     "elapsed": 6473,
     "status": "ok",
     "timestamp": 1445965583467,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "d9wMtjy5hCj9",
    "outputId": "3dd79c80-454a-4be0-8b71-4a4a357b3367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' of one eight f', 'self an anarchi', 'december one ni', 'eceived the ful', 'kunin as their ', 'n the one eight', 'clude emma gold', 'the assassinati', 'archism see bel', ' the cgt saw li', 'on federations ', ' s two zero s a', 'ion of one nine', 'ontrol for them', 'rm continues to', 'ian fascism was', 'ers supported b', 'nti fascist act', ' freedom christ', 'ro s strands of', 'story thus the ', 'ed the state ha', 't anarchism tak', 'me anarcho capi', 'itting another ', ' throughout the', 'r than speaking', 'sm rejects the ', ' in magazines s', 'means let alone', 'avors a non hie', ' such as the wo', 'ist cause both ', 'ed parliamentar', 'iticisms of ana', 's book european', 'anarchism has b', ' fascists he al', ' in most of wes', 'more extensive ', 't the list of a', 'ations hundreds', 'tal health give', ' autism for rea', 'ddle of the twe', 'y read until on', 'st terminology ', ' for autism eit', 'd that although', 'ldhood that man', 'nderreactivity ', 'd that sensory ', 'utism are unint', 'nd take of non ', 'not match those', 'get through to ', 'ing people with', 'd around them m', 'can make friend', 'sorders typical', ' such as eye to', 'eotyped pattern', ' autism is much', 'ing and may ref']\n",
      "[' anarchism orig']\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "seq_length = 15\n",
    "\n",
    "class BatchGenerator(object):\n",
    "  def __init__(self, text, batch_size, seq_length):\n",
    "    segment_length = seq_length * batch_size\n",
    "    len_text = len(text)//segment_length*segment_length\n",
    "    self._text = text[:len_text]\n",
    "    self._text_size = len_text\n",
    "    self._batch_size = batch_size\n",
    "    self._seq_length = seq_length\n",
    "    self._cursor = [ offset * segment_length for offset in range(batch_size)]\n",
    "  \n",
    "\n",
    "  \n",
    "  def next(self):\n",
    "    \"\"\"Generate the next array of batches from the data. \n",
    "    \"\"\"\n",
    "    batches = []\n",
    "    for step in range(self._batch_size):\n",
    "      batches.append(self._text[self._cursor[step]:self._cursor[step]+self._seq_length])\n",
    "      self._cursor[step] = (self._cursor[step] + self._seq_length)\n",
    "    return batches\n",
    "\n",
    "def characters(probabilities):\n",
    "  \"\"\"Turn a 1-hot encoding or a probability distribution over the possible\n",
    "  characters back into its (most likely) character representation.\"\"\"\n",
    "  return [id2char(c) for c in np.argmax(probabilities, 1)]\n",
    "\n",
    "\n",
    "def prediction_to_str(predictions):\n",
    "    return ''.join([characters(pred)[0] for pred in predictions])\n",
    "\n",
    "\n",
    "\n",
    "train_batches = BatchGenerator(train_text, batch_size, seq_length)\n",
    "valid_batches = BatchGenerator(valid_text, 1, seq_length)\n",
    "\n",
    "print(train_batches.next())\n",
    "print(valid_batches.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_units = 64\n",
    "embedding_size = 30\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    train_encoder_inputs = [tf.placeholder(tf.int32, shape=(None,)) for x in range(seq_length)]\n",
    "    train_decoder_inputs = [tf.placeholder(tf.int32, shape=(None,)) for x in range(seq_length+1)]\n",
    "    train_targets = [tf.placeholder(tf.int32, shape=(None,)) for x in range(seq_length+1)]\n",
    "\n",
    "    train_weights = [tf.constant(1.0) for x in range(seq_length+1)]\n",
    "\n",
    "    cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "\n",
    "    with tf.variable_scope(\"s2s\"):\n",
    "        outputs, states = tf.nn.seq2seq.embedding_rnn_seq2seq(train_encoder_inputs, train_decoder_inputs, cell,vocabulary_size, \n",
    "                                                              vocabulary_size, embedding_size)\n",
    "\n",
    "    train_loss = tf.nn.seq2seq.sequence_loss(outputs, train_targets, train_weights) \n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(train_loss)\n",
    "\n",
    "\n",
    "    validation_encoder_inputs =  [tf.placeholder(tf.int32, shape=(1,)) for x in range(seq_length)]\n",
    "    validation_decoder_inputs = [tf.placeholder(tf.int32, shape=(1,)) for x in range(seq_length+1)]\n",
    "    validation_targets = [tf.placeholder(tf.int32, shape=(1,)) for x in range(seq_length+1)] \n",
    "\n",
    "    validation_weights =  [tf.constant(1.0) for x in range(seq_length+1)]\n",
    "\n",
    "    with tf.variable_scope(\"s2s\", reuse = True):\n",
    "        validation_outputs, validation_states = tf.nn.seq2seq.embedding_rnn_seq2seq(validation_encoder_inputs, validation_decoder_inputs,\n",
    "                                                                                    cell, vocabulary_size, vocabulary_size, embedding_size,\n",
    "                                                                                    feed_previous=True)\n",
    "    validation_predictions = tf.pack([output for output in validation_outputs])\n",
    "    validation_loss = tf.nn.seq2seq.sequence_loss(validation_outputs, validation_targets, validation_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "step: 0\n",
      "loss:  3.34634\n",
      "input:  inated as a ter\n",
      "mirror input:  detani sa a ret\n",
      "prediction:    sssssssssnntsss\n",
      "================================================================================\n",
      "step: 1000\n",
      "loss:  2.73117\n",
      "input:  m of abuse firs\n",
      "mirror input:  m fo esuba srif\n",
      "prediction:     e e ea aa aa <eos>\n",
      "================================================================================\n",
      "step: 2000\n",
      "loss:  2.86431\n",
      "input:  t used against \n",
      "mirror input:  t desu tsniaga \n",
      "prediction:     ets sita erna \n",
      "================================================================================\n",
      "step: 3000\n",
      "loss:  3.05266\n",
      "input:  early working c\n",
      "mirror input:  ylrae gnikrow c\n",
      "prediction:    rerani rotna o<eos>\n",
      "================================================================================\n",
      "step: 4000\n",
      "loss:  2.71172\n",
      "input:  lass radicals i\n",
      "mirror input:  ssal slacidar i\n",
      "prediction:    ssa lalidsna da\n",
      "================================================================================\n",
      "step: 5000\n",
      "loss:  3.49797\n",
      "input:  ncluding the di\n",
      "mirror input:  gnidulcn eht id\n",
      "prediction:    naditno dihl ht\n",
      "================================================================================\n",
      "step: 6000\n",
      "loss:  4.86864\n",
      "input:  ggers of the en\n",
      "mirror input:  sregg fo eht ne\n",
      "prediction:    sret no eht eco\n",
      "================================================================================\n",
      "step: 7000\n",
      "loss:  4.4078\n",
      "input:  glish revolutio\n",
      "mirror input:  hsilg oitulover\n",
      "prediction:    silo ehtilugnor\n",
      "================================================================================\n",
      "step: 8000\n",
      "loss:  1.06272\n",
      "input:  n and the sans \n",
      "mirror input:  n dna eht snas \n",
      "prediction:    n dna eht sasn \n",
      "================================================================================\n",
      "step: 9000\n",
      "loss:  4.70765\n",
      "input:  culottes of the\n",
      "mirror input:  settoluc fo eht\n",
      "prediction:    tseloct eht uof\n",
      "================================================================================\n",
      "step: 10000\n",
      "loss:  5.57495\n",
      "input:   french revolut\n",
      "mirror input:   hcnerf tulover\n",
      "prediction:     nehtc rluocem \n",
      "================================================================================\n",
      "step: 11000\n",
      "loss:  3.39211\n",
      "input:  ion whilst the \n",
      "mirror input:  noi tslihw eht \n",
      "prediction:    noi shtil dew o\n",
      "================================================================================\n",
      "step: 12000\n",
      "loss:  1.62135\n",
      "input:  term is still u\n",
      "mirror input:  mret si llits u\n",
      "prediction:    remt sil lits u\n",
      "================================================================================\n",
      "step: 13000\n",
      "loss:  1.71725\n",
      "input:  sed in a pejora\n",
      "mirror input:  des ni a arojep\n",
      "prediction:    des ni a roatep\n",
      "================================================================================\n",
      "step: 14000\n",
      "loss:  3.8942\n",
      "input:  tive way to des\n",
      "mirror input:  evit yaw ot sed\n",
      "prediction:    evit aw yero si\n",
      "================================================================================\n",
      "step: 15000\n",
      "loss:  2.25178\n",
      "input:  cribe any act t\n",
      "mirror input:  ebirc yna tca t\n",
      "prediction:    evilb yra ctu f\n",
      "================================================================================\n",
      "step: 16000\n",
      "loss:  3.28128\n",
      "input:  hat used violen\n",
      "mirror input:  tah desu neloiv\n",
      "prediction:    tah des nuolevi\n",
      "================================================================================\n",
      "step: 17000\n",
      "loss:  3.35318\n",
      "input:  t means to dest\n",
      "mirror input:  t snaem ot tsed\n",
      "prediction:    t sname t stoed\n",
      "================================================================================\n",
      "step: 18000\n",
      "loss:  2.23558\n",
      "input:  roy the organiz\n",
      "mirror input:  yor eht zinagro\n",
      "prediction:    yor eht vinorat\n",
      "================================================================================\n",
      "step: 19000\n",
      "loss:  1.55075\n",
      "input:  ation of societ\n",
      "mirror input:  noita fo teicos\n",
      "prediction:    noita fo tiesoc\n",
      "================================================================================\n",
      "step: 20000\n",
      "loss:  2.88483\n",
      "input:  y it has also b\n",
      "mirror input:  y ti sah osla b\n",
      "prediction:    y ti sah sob ap\n",
      "================================================================================\n",
      "step: 21000\n",
      "loss:  0.301486\n",
      "input:  een taken up as\n",
      "mirror input:  nee nekat pu sa\n",
      "prediction:    nee nekat pu sa\n",
      "================================================================================\n",
      "step: 22000\n",
      "loss:  0.702455\n",
      "input:   a positive lab\n",
      "mirror input:   a evitisop bal\n",
      "prediction:     a evitisob pav\n",
      "================================================================================\n",
      "step: 23000\n",
      "loss:  6.46809\n",
      "input:  el by self defi\n",
      "mirror input:  le yb fles ifed\n",
      "prediction:    yl el fif edlao\n",
      "================================================================================\n",
      "step: 24000\n",
      "loss:  5.34492\n",
      "input:  ned anarchists \n",
      "mirror input:  den stsihcrana \n",
      "prediction:    sde tnisrahcac \n",
      "================================================================================\n",
      "step: 25000\n",
      "loss:  1.55361\n",
      "input:  the word anarch\n",
      "mirror input:  eht drow hcrana\n",
      "prediction:    eht drohw crana\n",
      "================================================================================\n",
      "step: 26000\n",
      "loss:  2.34613\n",
      "input:  ism is derived \n",
      "mirror input:  msi si devired \n",
      "prediction:    msi si devird e\n",
      "================================================================================\n",
      "step: 27000\n",
      "loss:  1.93863\n",
      "input:  from the greek \n",
      "mirror input:  morf eht keerg \n",
      "prediction:    morf eht ekger \n",
      "================================================================================\n",
      "step: 28000\n",
      "loss:  3.41241\n",
      "input:  without archons\n",
      "mirror input:  tuohtiw snohcra\n",
      "prediction:    tuhtoiw snoohcr\n",
      "================================================================================\n",
      "step: 29000\n",
      "loss:  0.325275\n",
      "input:   ruler chief ki\n",
      "mirror input:   relur feihc ik\n",
      "prediction:     relur feihc in\n",
      "================================================================================\n",
      "step: 30000\n",
      "loss:  2.20477\n",
      "input:  ng anarchism as\n",
      "mirror input:  gn msihcrana sa\n",
      "prediction:    gn smihcaran sa\n",
      "================================================================================\n",
      "step: 31000\n",
      "loss:  0.0650293\n",
      "input:   a political ph\n",
      "mirror input:   a lacitilop hp\n",
      "prediction:     a lacitilop hp\n",
      "================================================================================\n",
      "step: 32000\n",
      "loss:  0.159005\n",
      "input:  ilosophy is the\n",
      "mirror input:  yhposoli si eht\n",
      "prediction:    yhposoli si eht\n",
      "================================================================================\n",
      "step: 33000\n",
      "loss:  0.054695\n",
      "input:   belief that ru\n",
      "mirror input:   feileb taht ur\n",
      "prediction:     feileb taht ur\n",
      "================================================================================\n",
      "step: 34000\n",
      "loss:  1.89042\n",
      "input:  lers are unnece\n",
      "mirror input:  srel era ecennu\n",
      "prediction:    srel era enecua\n",
      "================================================================================\n",
      "step: 35000\n",
      "loss:  0.0720994\n",
      "input:  ssary and shoul\n",
      "mirror input:  yrass dna luohs\n",
      "prediction:    yrass dna luohs\n",
      "================================================================================\n",
      "step: 36000\n",
      "loss:  0.107705\n",
      "input:  d be abolished \n",
      "mirror input:  d eb dehsiloba \n",
      "prediction:    d eb dehsiloba \n",
      "================================================================================\n",
      "step: 37000\n",
      "loss:  0.0444735\n",
      "input:  although there \n",
      "mirror input:  hguohtla ereht \n",
      "prediction:    hguohtla ereht \n",
      "================================================================================\n",
      "step: 38000\n",
      "loss:  2.22899\n",
      "input:  are differing i\n",
      "mirror input:  era gnireffid i\n",
      "prediction:    era gnifrebif i\n",
      "================================================================================\n",
      "step: 39000\n",
      "loss:  2.6021\n",
      "input:  nterpretations \n",
      "mirror input:  snoitaterpretn \n",
      "prediction:    snoitatrepnert \n",
      "================================================================================\n",
      "step: 40000\n",
      "loss:  0.059551\n",
      "input:  of what this me\n",
      "mirror input:  fo tahw siht em\n",
      "prediction:    fo tahw siht em\n",
      "================================================================================\n",
      "step: 41000\n",
      "loss:  3.12119\n",
      "input:  ans anarchism a\n",
      "mirror input:  sna msihcrana a\n",
      "prediction:    sna smicnarha t\n",
      "================================================================================\n",
      "step: 42000\n",
      "loss:  0.821996\n",
      "input:  lso refers to r\n",
      "mirror input:  osl srefer ot r\n",
      "prediction:    osl srefer or t\n",
      "================================================================================\n",
      "step: 43000\n",
      "loss:  1.61079\n",
      "input:  elated social m\n",
      "mirror input:  detale laicos m\n",
      "prediction:    detala elicos a\n",
      "================================================================================\n",
      "step: 44000\n",
      "loss:  0.0420702\n",
      "input:  ovements that a\n",
      "mirror input:  stnemevo taht a\n",
      "prediction:    stnemevo taht a\n",
      "================================================================================\n",
      "step: 45000\n",
      "loss:  7.76884\n",
      "input:  dvocate the eli\n",
      "mirror input:  etacovd eht ile\n",
      "prediction:    etacko sir eeh \n",
      "================================================================================\n",
      "step: 46000\n",
      "loss:  0.990068\n",
      "input:  mination of aut\n",
      "mirror input:  noitanim fo tua\n",
      "prediction:    noitanim fo uta\n",
      "================================================================================\n",
      "step: 47000\n",
      "loss:  3.35855\n",
      "input:  horitarian inst\n",
      "mirror input:  nairatiroh tsni\n",
      "prediction:    nairatiro htsin\n",
      "================================================================================\n",
      "step: 48000\n",
      "loss:  3.60164\n",
      "input:  itutions partic\n",
      "mirror input:  snoituti citrap\n",
      "prediction:    snoitutic tirpa\n",
      "================================================================================\n",
      "step: 49000\n",
      "loss:  0.0308867\n",
      "input:  ularly the stat\n",
      "mirror input:  ylralu eht tats\n",
      "prediction:    ylralu eht tats\n",
      "================================================================================\n",
      "step: 50000\n",
      "loss:  0.0425498\n",
      "input:  e the word anar\n",
      "mirror input:  e eht drow rana\n",
      "prediction:    e eht drow rana\n",
      "================================================================================\n",
      "step: 51000\n",
      "loss:  5.50936\n",
      "input:  chy as most ana\n",
      "mirror input:  yhc sa tsom ana\n",
      "prediction:    yhc s sato nat \n",
      "================================================================================\n",
      "step: 52000\n",
      "loss:  1.47299\n",
      "input:  rchists use it \n",
      "mirror input:  stsihcr esu ti \n",
      "prediction:    stsihcr est uo \n",
      "================================================================================\n",
      "step: 53000\n",
      "loss:  4.85133\n",
      "input:  does not imply \n",
      "mirror input:  seod ton ylpmi \n",
      "prediction:    seod to ylnpm i\n",
      "================================================================================\n",
      "step: 54000\n",
      "loss:  4.57241\n",
      "input:  chaos nihilism \n",
      "mirror input:  soahc msilihin \n",
      "prediction:    saohm sicnilhp \n",
      "================================================================================\n",
      "step: 55000\n",
      "loss:  0.0857874\n",
      "input:  or anomie but r\n",
      "mirror input:  ro eimona tub r\n",
      "prediction:    ro eimona tub r\n",
      "================================================================================\n",
      "step: 56000\n",
      "loss:  0.0768319\n",
      "input:  ather a harmoni\n",
      "mirror input:  rehta a inomrah\n",
      "prediction:    rehta a inomrah\n",
      "================================================================================\n",
      "step: 57000\n",
      "loss:  2.05379\n",
      "input:  ous anti author\n",
      "mirror input:  suo itna rohtua\n",
      "prediction:    suo nita rohtua\n",
      "================================================================================\n",
      "step: 58000\n",
      "loss:  1.39611\n",
      "input:  itarian society\n",
      "mirror input:  nairati yteicos\n",
      "prediction:    nairati yeticot\n",
      "================================================================================\n",
      "step: 59000\n",
      "loss:  0.0258572\n",
      "input:   in place of wh\n",
      "mirror input:   ni ecalp fo hw\n",
      "prediction:     ni ecalp fo hw\n",
      "================================================================================\n",
      "step: 60000\n",
      "loss:  7.09083\n",
      "input:  at are regarded\n",
      "mirror input:  ta era dedrager\n",
      "prediction:    ta er dedargerg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for step in range(60001):\n",
    "        \n",
    "    \n",
    "        input_batches = train_batches.next()\n",
    "        mirror_batches = [mirror_words(seq) for seq in input_batches]\n",
    "        train_encoder_inputs_data = [[char2id(seq[i]) for seq in input_batches] for i in range(seq_length)]\n",
    "        train_decoder_inputs_data = [[1] * batch_size] +  [[char2id(seq[i]) for seq in mirror_batches]  for i in range(seq_length)]\n",
    "        train_targets_data = [[char2id(seq[i]) for seq in mirror_batches]  for i in range(seq_length)] + [[2] * batch_size]\n",
    "        feed_dict = dict(zip(train_encoder_inputs+train_decoder_inputs+train_targets,\n",
    "                             train_encoder_inputs_data+train_decoder_inputs_data+train_targets_data))\n",
    "        \n",
    "        sess.run(train_step, feed_dict=feed_dict)\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "\n",
    "            \n",
    "            validation_input_batches = valid_batches.next()\n",
    "            validation_mirror_batches = [mirror_words(seq) for seq in validation_input_batches]\n",
    "            \n",
    "            validation_encoder_inputs_data = [[char2id(validation_input_batches[0][i])] for i in range(seq_length)]\n",
    "            validation_targets_data = [[char2id(validation_mirror_batches[0][i])]  for i in range(seq_length)] + [[2]]\n",
    "            feed_dict = dict(zip(validation_encoder_inputs+validation_targets,\n",
    "                             validation_encoder_inputs_data+validation_targets_data))\n",
    "            feed_dict[validation_decoder_inputs[0]] = [1] # <go>\n",
    "            loss , predictions = sess.run([validation_loss, validation_predictions], feed_dict=feed_dict)\n",
    "            print(\"=\"*80)\n",
    "            print('step:',step)\n",
    "            print('loss: ', loss)\n",
    "            print('input: ', validation_input_batches[0])\n",
    "            print('mirror input: ', validation_mirror_batches[0])\n",
    "            print('prediction:   ', prediction_to_str(predictions[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "6_lstm.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
